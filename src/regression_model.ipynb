{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.typing as npt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "from definitions import ALPHA\n",
    "from battery_data import test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECIMAL_PLACES = 2\n",
    "\n",
    "def index_to_predictor_variable(index: int) -> str:\n",
    "    if index == 0:\n",
    "        return 'intercept'\n",
    "    \n",
    "    return f'x{index}'\n",
    "\n",
    "def mse(y: npt.NDArray, y_pred: npt.NDArray) -> float:\n",
    "    n = len(y)\n",
    "    return 1 / n * np.sum((y - y_pred) ** 2)\n",
    "\n",
    "def smape(y: npt.NDArray, y_pred: npt.NDArray) -> float:\n",
    "    n = len(y)\n",
    "    return 1 / n * np.sum(np.abs(y - y_pred) / ((np.abs(y) + np.abs(y_pred)) / 2)) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insignificant_predictors</th>\n",
       "      <th>r_squared</th>\n",
       "      <th>r_squared_adjusted</th>\n",
       "      <th>aic</th>\n",
       "      <th>bic</th>\n",
       "      <th>f_statistic_p_value</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>smape</th>\n",
       "      <th>smape_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polynomial_degree</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>85363.26</td>\n",
       "      <td>85389.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>84664.21</td>\n",
       "      <td>84699.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>9.08</td>\n",
       "      <td>8.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>82798.30</td>\n",
       "      <td>82842.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8.87</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>82369.84</td>\n",
       "      <td>82422.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>82362.83</td>\n",
       "      <td>82424.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>81997.70</td>\n",
       "      <td>82068.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>81942.58</td>\n",
       "      <td>82021.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>intercept,x1,x2,x3,x4,x5,x6,x7,x8,x9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>81999.20</td>\n",
       "      <td>82087.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>8.67</td>\n",
       "      <td>8.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>intercept,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>81945.54</td>\n",
       "      <td>82033.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   insignificant_predictors  r_squared  \\\n",
       "polynomial_degree                                                        \n",
       "2                                                      None       0.73   \n",
       "3                                                      None       0.74   \n",
       "4                                                      None       0.75   \n",
       "5                                                      None       0.75   \n",
       "6                                                      None       0.75   \n",
       "7                                                      None       0.75   \n",
       "8                                                      None       0.75   \n",
       "9                      intercept,x1,x2,x3,x4,x5,x6,x7,x8,x9       0.75   \n",
       "10                 intercept,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10       0.75   \n",
       "\n",
       "                   r_squared_adjusted       aic       bic  \\\n",
       "polynomial_degree                                           \n",
       "2                                0.73  85363.26  85389.69   \n",
       "3                                0.74  84664.21  84699.44   \n",
       "4                                0.75  82798.30  82842.34   \n",
       "5                                0.75  82369.84  82422.69   \n",
       "6                                0.75  82362.83  82424.49   \n",
       "7                                0.75  81997.70  82068.17   \n",
       "8                                0.75  81942.58  82021.85   \n",
       "9                                0.75  81999.20  82087.28   \n",
       "10                               0.75  81945.54  82033.62   \n",
       "\n",
       "                   f_statistic_p_value   mse  mse_test  smape  smape_test  \n",
       "polynomial_degree                                                          \n",
       "2                                  0.0  0.33      0.33   9.13        8.71  \n",
       "3                                  0.0  0.32      0.33   9.08        8.66  \n",
       "4                                  0.0  0.31      0.30   8.87        8.22  \n",
       "5                                  0.0  0.31      0.31   8.78        8.22  \n",
       "6                                  0.0  0.31      0.31   8.78        8.22  \n",
       "7                                  0.0  0.31      0.30   8.71        8.11  \n",
       "8                                  0.0  0.31      0.30   8.70        8.11  \n",
       "9                                  0.0  0.31      0.31   8.67        8.18  \n",
       "10                                 0.0  0.31      0.30   8.70        8.12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MIN_POLYNOMIAL_DEGREE = 2\n",
    "MAX_POLYNOMIAL_DEGREE = 10\n",
    "DECIMAL_PLACES = 2\n",
    "\n",
    "model_statistics = pd.DataFrame(columns=[\n",
    "    'insignificant_predictors',\n",
    "    'r_squared',\n",
    "    'r_squared_adjusted',\n",
    "    'aic',\n",
    "    'bic',\n",
    "    'f_statistic_p_value',\n",
    "    'mse',\n",
    "    'mse_test',\n",
    "    'smape',\n",
    "    'smape_test',\n",
    "])\n",
    "model_statistics.index.names = ['polynomial_degree']\n",
    "\n",
    "for polynomial_degree in range(MIN_POLYNOMIAL_DEGREE, MAX_POLYNOMIAL_DEGREE + 1):\n",
    "    polynomial_transformer = PolynomialFeatures(degree=polynomial_degree, include_bias=True) # Set include_bias=True to add a column of 1s to the array, such that the polynomial model becomes: Y = β_0 * 1 + β_1 * x^1 + ... + β_p * x^p + e. This column of 1s represents the intercept term β_0\n",
    "    x = train.logged['capacity'].to_numpy()\n",
    "    X = polynomial_transformer.fit_transform(x.reshape((-1, 1)))\n",
    "    y = train.logged['RUL'].to_numpy()\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    X_test = polynomial_transformer.fit_transform(test.logged['capacity'].to_numpy().reshape((-1, 1)))\n",
    "    y_test = test.logged['RUL'].to_numpy()\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    insignificant_predictors = [index_to_predictor_variable(index) for index, p_value in enumerate(model.pvalues) if p_value > ALPHA]\n",
    "    insignificant_predictors_str = ','.join(insignificant_predictors) if insignificant_predictors else 'None'\n",
    "\n",
    "    statistics_models_new = pd.DataFrame({\n",
    "        'insignificant_predictors': insignificant_predictors_str,\n",
    "        'r_squared': model.rsquared,\n",
    "        'r_squared_adjusted': model.rsquared_adj,\n",
    "        'aic': model.aic,\n",
    "        'bic': model.bic,\n",
    "        'f_statistic_p_value': model.f_pvalue,\n",
    "        'mse': model.mse_resid,\n",
    "        'mse_test': mse(y_test, y_test_pred),\n",
    "        'smape': smape(y, y_pred),\n",
    "        'smape_test': smape(y_test, y_test_pred),\n",
    "    }, index=[polynomial_degree])\n",
    "    statistics_models_new.index.names = ['polynomial_degree']\n",
    "    model_statistics = pd.concat([model_statistics, statistics_models_new])\n",
    "\n",
    "model_statistics_rounded = model_statistics.copy()\n",
    "numeric_columns = [column for column in model_statistics_rounded if model_statistics_rounded[column].dtype == 'float64']\n",
    "model_statistics_rounded[numeric_columns] = model_statistics_rounded[numeric_columns].apply(lambda x: np.round(x, DECIMAL_PLACES))\n",
    "display(model_statistics_rounded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-2.78e+08', '2.22e+09', '-7.77e+09', '1.55e+10', '-1.93e+10',\n",
       "       '1.54e+10', '-7.66e+09', '2.18e+09', '-2.70e+08'], dtype='<U9')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.751</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.751</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.866e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 16 Apr 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:19:06</td>     <th>  Log-Likelihood:    </th> <td> -40962.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 49433</td>      <th>  AIC:               </th> <td>8.194e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 49424</td>      <th>  BIC:               </th> <td>8.202e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-2.776e+08</td> <td> 3.21e+07</td> <td>   -8.636</td> <td> 0.000</td> <td>-3.41e+08</td> <td>-2.15e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 2.221e+09</td> <td> 2.61e+08</td> <td>    8.502</td> <td> 0.000</td> <td> 1.71e+09</td> <td> 2.73e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-7.766e+09</td> <td> 9.28e+08</td> <td>   -8.367</td> <td> 0.000</td> <td>-9.59e+09</td> <td>-5.95e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  1.55e+10</td> <td> 1.88e+09</td> <td>    8.233</td> <td> 0.000</td> <td> 1.18e+10</td> <td> 1.92e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-1.933e+10</td> <td> 2.39e+09</td> <td>   -8.100</td> <td> 0.000</td> <td> -2.4e+10</td> <td>-1.46e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  1.54e+10</td> <td> 1.93e+09</td> <td>    7.966</td> <td> 0.000</td> <td> 1.16e+10</td> <td> 1.92e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-7.664e+09</td> <td> 9.78e+08</td> <td>   -7.833</td> <td> 0.000</td> <td>-9.58e+09</td> <td>-5.75e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 2.177e+09</td> <td> 2.83e+08</td> <td>    7.700</td> <td> 0.000</td> <td> 1.62e+09</td> <td> 2.73e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>-2.703e+08</td> <td> 3.57e+07</td> <td>   -7.567</td> <td> 0.000</td> <td> -3.4e+08</td> <td>   -2e+08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3641.356</td> <th>  Durbin-Watson:     </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1984.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.339</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.290</td>  <th>  Cond. No.          </th> <td>5.46e+12</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.06e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.751\n",
       "Model:                            OLS   Adj. R-squared:                  0.751\n",
       "Method:                 Least Squares   F-statistic:                 1.866e+04\n",
       "Date:                Sun, 16 Apr 2023   Prob (F-statistic):               0.00\n",
       "Time:                        00:19:06   Log-Likelihood:                -40962.\n",
       "No. Observations:               49433   AIC:                         8.194e+04\n",
       "Df Residuals:                   49424   BIC:                         8.202e+04\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -2.776e+08   3.21e+07     -8.636      0.000   -3.41e+08   -2.15e+08\n",
       "x1          2.221e+09   2.61e+08      8.502      0.000    1.71e+09    2.73e+09\n",
       "x2         -7.766e+09   9.28e+08     -8.367      0.000   -9.59e+09   -5.95e+09\n",
       "x3           1.55e+10   1.88e+09      8.233      0.000    1.18e+10    1.92e+10\n",
       "x4         -1.933e+10   2.39e+09     -8.100      0.000    -2.4e+10   -1.46e+10\n",
       "x5           1.54e+10   1.93e+09      7.966      0.000    1.16e+10    1.92e+10\n",
       "x6         -7.664e+09   9.78e+08     -7.833      0.000   -9.58e+09   -5.75e+09\n",
       "x7          2.177e+09   2.83e+08      7.700      0.000    1.62e+09    2.73e+09\n",
       "x8         -2.703e+08   3.57e+07     -7.567      0.000    -3.4e+08      -2e+08\n",
       "==============================================================================\n",
       "Omnibus:                     3641.356   Durbin-Watson:                   0.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1984.648\n",
       "Skew:                           0.339   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.290   Cond. No.                     5.46e+12\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.06e-20. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "POLYNOMIAL_DEGREE = 8\n",
    "\n",
    "polynomial_transformer = PolynomialFeatures(degree=POLYNOMIAL_DEGREE, include_bias=True)\n",
    "x = train.logged['capacity'].to_numpy()\n",
    "X = polynomial_transformer.fit_transform(x.reshape((-1, 1)))\n",
    "y = train.logged['RUL'].to_numpy()\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "scientific_round_vectorized = np.vectorize(np.format_float_scientific)\n",
    "display(scientific_round_vectorized(model.params, DECIMAL_PLACES))\n",
    "display(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
